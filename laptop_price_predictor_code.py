# -*- coding: utf-8 -*-
"""laptop_price_predictor_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Eag0Lt58UMeVKMRUgnsoUcMjXBmXWGli
"""

import numpy as np
import pandas as pd

df=pd.read_csv('laptop_data.csv')

"""# DATA INTRODUCTION"""

df.head()

df.shape

#info : data types

df.info()

#to check duplicate rows

df.duplicated().sum()

#missing values in each coulumn

df.isnull().sum()

"""# DATA CLEANSING"""

#removing unnamed column

df.drop(columns=['Unnamed: 0'], inplace= True)

df.head()

#remove GB from RAM and Weight => converted to int data type

df['Ram']=df['Ram'].str.replace('GB','')
df['Weight']=df['Weight'].str.replace('kg','')

df.head()

#changing data type

df['Ram']=df['Ram'].astype('int32')
df['Weight']=df['Weight'].astype('float32')

df.info()

"""# EDA: EXPLORATORY DATA ANALYSIS AND FEATURE ENGINEERING

#### (both uni and bi-variate)
"""

#univariate analysis on price column

#suppress warning
import warnings
warnings.filterwarnings('ignore')

import seaborn as sns

sns.distplot(df['Price'])

#note:
#data is skewed=> economy laptops: high density and expensive laptops: low density
# because the data is skewed a few algorithms might be difficult to converge

"""### 1:brand-wise laptops"""

df['Company'].value_counts().plot(kind='bar')

"""### 2:avg price for each brand"""

import matplotlib.pyplot as plt

sns.barplot(x=df['Company'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

"""### 3:TYPE OF LAPTOPS"""

df['TypeName'].value_counts().plot(kind='bar')

"""### 4:avg price for each type"""

sns.barplot(x=df['TypeName'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

"""### 5: analysing size density"""

sns.distplot(df['Inches'])

sns.scatterplot(x=df['Inches'],y=df['Price'])

"""### 6:screen resolution"""

df['ScreenResolution'].value_counts()

#note:
# touchscreen y/n
# resolution a*b given in each type
#ips panel y/n

"""###    a: touchscreen or not"""

#df['TouchScreen']=df['ScreenResolution'].apply(lambda x:1 if 'TouchScreen' in x else 0)
df['TouchScreen'] = df['ScreenResolution'].apply(lambda x: 1 if 'Touchscreen' in x else 0)

df.sample(5)

"""### b: count of touchscreen laptops"""

df['TouchScreen'].value_counts().plot(kind='bar')

"""### c: avg price as per touchscreen"""

sns.barplot(x=df['TouchScreen'], y=df['Price'])

"""### 7: feature engineering: create ips panel column(we are adding a feature)"""

df['IPS'] = df['ScreenResolution'].apply(lambda x: 1 if 'IPS' in x else 0)

df.sample(5)

"""### a: count of IPS laptops"""

df['IPS'].value_counts().plot(kind='bar')

"""### b: avg price as per IPS"""

sns.barplot(x=df['IPS'], y=df['Price'])

# NOTE:  ips displays => more price

"""### 8: x and y resolution"""

new = df['ScreenResolution'].str.split('x', n=1, expand=True)

df['X_res']= new[0]
df['Y_res']=new[1]
df.head()

df['X_res'] = df['X_res'].str.replace(',','').str.findall(r'(\d+\.?\d+)').apply(lambda x:x[0])

df.head()

df.info()

# x and y resolutions should be integers

df['X_res']=df['X_res'].astype('int32')
df['Y_res']=df['Y_res'].astype('int32')

df.info()

df.corr(numeric_only = True)['Price']

"""### 9: PPI: PIXEL PER INCH

#### ppi=sqrt(xres^2+yres^2)/inches
"""

df['ppi']=(((df['X_res']**2) + (df['Y_res']**2))**0.5/df['Inches']).astype('float')

df.corr(numeric_only = True)['Price']

#Hence, rather than using xres, yres or inches, we will use ppi

"""### removing screeres, xres, yres, and inches"""

df.drop(columns=['ScreenResolution'],inplace=True)
df.head()

df.drop(columns=['Inches','X_res','Y_res'],inplace=True)

df.head()

"""### 10: CPU"""

df['Cpu'].value_counts()

#note: 118 different categories, feature engineering recquired

"""### extract first 3 words"""

df['Cpu Name']=df['Cpu'].apply(lambda x:" ".join(x.split()[0:3]))

df.head()

def fetch_processor(text):
    if text == 'Intel Core i7' or text == 'Intel Core i5' or text == 'Intel Core i3':
        return text
    else:
        if text.split()[0] == 'Intel':
            return 'Other Intel Processor'
        else:
            return 'AMD Processor'

df['Cpu brand']=df['Cpu Name'].apply(fetch_processor)

df.head()

df['Cpu brand'].value_counts().plot(kind='bar')

sns.barplot(x=df['Cpu brand'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

"""### Cpu brand is quite important in determining price, lets drop other cpu columns"""

df.drop(columns=['Cpu','Cpu Name'],inplace= True)

df.head()

"""# 11: RAM"""

df['Ram'].value_counts().plot(kind='bar')

sns.barplot(x=df['Ram'],y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

"""### observation: price increases linearly with ram, therefore ram is extremely imp to predict the price of any laptop

# 12: Memory
"""

df['Memory'].value_counts()

# split mem into 4 cols: ssd, hdd and two others// code below

df['Memory'] = df['Memory'].astype(str).replace('\.0', '', regex=True)
df["Memory"] = df["Memory"].str.replace('GB', '')
df["Memory"] = df["Memory"].str.replace('TB', '000')
new = df["Memory"].str.split("+", n = 1, expand = True)
print(new)

df["first"]= new[0]
df["first"]=df["first"].str.strip()

df["second"]= new[1]

df["Layer1HDD"] = df["first"].apply(lambda x: 1 if "HDD" in x else 0)
df["Layer1SSD"] = df["first"].apply(lambda x: 1 if "SSD" in x else 0)
df["Layer1Hybrid"] = df["first"].apply(lambda x: 1 if "Hybrid" in x else 0)
df["Layer1Flash_Storage"] = df["first"].apply(lambda x: 1 if "Flash Storage" in x else 0)

df['first'] = df['first'].str.replace(r'\D', '')

df["second"].fillna("0", inplace = True)

df["Layer2HDD"] = df["second"].apply(lambda x: 1 if "HDD" in x else 0)
df["Layer2SSD"] = df["second"].apply(lambda x: 1 if "SSD" in x else 0)
df["Layer2Hybrid"] = df["second"].apply(lambda x: 1 if "Hybrid" in x else 0)
df["Layer2Flash_Storage"] = df["second"].apply(lambda x: 1 if "Flash Storage" in x else 0)

df['second'] = df['second'].str.replace(r'\D', '')


df['first'] = df['first'].str.extract('(\d+)').astype(float)
df['second'] = df['second'].str.extract('(\d+)').astype(float)

df["HDD"]=(df["first"]*df["Layer1HDD"]+df["second"]*df["Layer2HDD"])
df["SSD"]=(df["first"]*df["Layer1SSD"]+df["second"]*df["Layer2SSD"])
df["Hybrid"]=(df["first"]*df["Layer1Hybrid"]+df["second"]*df["Layer2Hybrid"])
df["Flash_Storage"]=(df["first"]*df["Layer1Flash_Storage"]+df["second"]*df["Layer2Flash_Storage"])
df.drop(columns=['Layer1HDD', 'Layer1SSD'],inplace=True)
df.drop(columns=['first'],inplace=True)
df.drop(columns=['second'],inplace=True)

df.head()

df.drop(columns=['Layer1Hybrid', 'Layer1Flash_Storage','Layer2HDD','Layer2SSD','Layer2Hybrid','Layer2Flash_Storage'],inplace=True)

df.head()

df.info()

df['HDD']=df['HDD'].astype('int32')
df['SSD']=df['SSD'].astype('int32')
df['Hybrid']=df['Hybrid'].astype('int32')
df['Flash_Storage']=df['Flash_Storage'].astype('int32')
df.sample(5)

df.drop(columns=['Memory'],inplace=True)

df.head()

df.corr(numeric_only = True)['Price']

# with HardDrive price has a weak negative correlation => harddrive up price down
#weak correlation apart from ssd

#observation: hence, we should only need ssd, but apparently ssd plus hdd will give better results

df.drop(columns=['Hybrid','Flash_Storage'],inplace=True)

df.head()

"""# 13: GPU"""

df['Gpu'].value_counts()

#too many categories. Also, many of them have occured just once, not suitable for modelling

#we will extract brand name

df['Gpu brand']=df['Gpu'].apply(lambda x:x.split()[0])

df.head()

df['Gpu brand'].value_counts().plot(kind='bar')

# just one arm Gpu, no use, remove that row

df = df[df['Gpu brand'] != 'ARM']
df['Gpu brand'].value_counts().plot(kind='bar')

sns.barplot(x=df['Gpu brand'],y=df['Price'], estimator=np.median)
plt.xticks(rotation='vertical')
plt.show()

df.drop(columns=['Gpu'], inplace = True)

df.head()

"""# 14: operating systems"""

df['OpSys'].value_counts()

#too many categories, reduction needed

sns.barplot(x=df['OpSys'], y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

def cat_os(inp):
    if inp == 'Windows 10' or inp == 'Windows 7' or inp == 'Windows 10 S':
        return 'Windows'
    elif inp == 'macOS' or inp == 'Mac OS X':
        return 'Mac'
    else:
        return 'Others/No OS/Linux'

df['os']=df['OpSys'].apply(cat_os)

df.head()

df.drop(columns=['OpSys'],inplace= True)

sns.barplot(x=df['os'], y=df['Price'])
plt.xticks(rotation='vertical')
plt.show()

"""# 15: weight"""

sns.distplot(df['Weight'])

sns.scatterplot(x=df['Weight'], y=df['Price'])

df.corr(numeric_only=True)['Price']

sns.heatmap(df.corr(numeric_only=True))

#In general, white flag implies strong correlation between independent cols, implies red flag, dono m se ek hi column rakhengey. not recquired here

# Going back, our target column(price) was skewed, which can trouble the algorithm, to fix that, use log

sns.distplot(np.log(df['Price']))

#by using log, r2 score increased by 5
#predict karte time use exp to get price

X= df.drop(columns=['Price'])
y=np.log(df['Price'])

X

y

"""# APPLYING MODELS

## SPLITTING DF INTO TESTING AND TRAINING DATA
"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train, y_test = train_test_split(X,y,test_size=0.15, random_state=2)

X_train

"""## IMPORTING DIFFERENT MODELS"""

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import r2_score, mean_absolute_error

from sklearn.linear_model import LinearRegression,Ridge,Lasso
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor,ExtraTreesRegressor
from sklearn.svm import SVR

"""### LINEAR REGRESSION"""

step1=ColumnTransformer(transformers=[
        ('col_tnf',OneHotEncoder(sparse=False, drop= 'first'),[0,1,7,10,11])
],remainder='passthrough')

step2 = LinearRegression()

pipe = Pipeline([
    ('step1',step1),
    ('step2',step2)

])

pipe.fit(X_train, y_train)

y_pred = pipe.predict(X_test)

print('R2 score', r2_score(y_test, y_pred))
print('MAE',mean_absolute_error(y_test, y_pred))

np.exp(0.21)

"""### RANDOM FOREST"""

step1 = ColumnTransformer(transformers=[
    ('col_tnf',OneHotEncoder(sparse=False,drop='first'),[0,1,7,10,11])
],remainder='passthrough')

step2 = RandomForestRegressor(n_estimators=100,
                              random_state=3,
                              max_samples=0.57,
                              max_features=0.78,
                              max_depth=15)

pipe = Pipeline([
    ('step1',step1),
    ('step2',step2)
])

pipe.fit(X_train,y_train)

y_pred = pipe.predict(X_test)

print('R2 score',r2_score(y_test,y_pred))
print('MAE',mean_absolute_error(y_test,y_pred))

"""### Exporting the model"""

import pickle

pickle.dump(df, open('df.pkl','wb'))
pickle.dump(pipe,open('pipe.pkl','wb'))

df

